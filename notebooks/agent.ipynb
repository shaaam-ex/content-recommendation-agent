{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/exton/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported and globals ready.\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Import necessary libraries and initialize global variables\n",
        "\n",
        "import pandas as pd\n",
        "import ast\n",
        "import re\n",
        "import json\n",
        "import requests\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import chromadb\n",
        "from chromadb.config import Settings\n",
        "\n",
        "# For calling the LLM router (OpenRouter client or OpenAI client)\n",
        "from openai import OpenAIError\n",
        "\n",
        "# Assuming open_router_client and ares_api_key are configured elsewhere in your environment\n",
        "\n",
        "print(\"Libraries imported and globals ready.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Time to give this output to an LLM\n",
        "import openai\n",
        "\n",
        "open_router_client = openai.OpenAI(\n",
        "    api_key=\"api-key\",\n",
        "    base_url=\"https://openrouter.ai/api/v1\" \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data loaded and cleaned.\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Load datasets, merge and clean relevant fields\n",
        "\n",
        "movies_df = pd.read_csv('../data/tmdb_5000_movies.csv')\n",
        "credits_df = pd.read_csv('../data/tmdb_5000_credits.csv')\n",
        "\n",
        "# Merge on movie title\n",
        "df = movies_df.merge(credits_df, on='title')\n",
        "\n",
        "# Helper function to parse JSON-like strings and extract 'name' fields\n",
        "def extract_names(json_str, top_n=None):\n",
        "    try:\n",
        "        items = ast.literal_eval(json_str)\n",
        "        names = [item['name'] for item in items]\n",
        "        if top_n:\n",
        "            names = names[:top_n]\n",
        "        return ', '.join(names)\n",
        "    except (ValueError, SyntaxError):\n",
        "        return ''\n",
        "\n",
        "# Apply the helper to genres, cast, and crew columns\n",
        "df['genres_clean'] = df['genres'].apply(lambda x: extract_names(x))\n",
        "df['cast_clean'] = df['cast'].apply(lambda x: extract_names(x, top_n=5))\n",
        "df['crew_clean'] = df['crew'].apply(lambda x: extract_names(x, top_n=5))\n",
        "\n",
        "print(\"Data loaded and cleaned.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Movie documents prepared.\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Build a single descriptive text block per movie for embedding\n",
        "\n",
        "def build_movie_document(row):\n",
        "    return f\"\"\"\n",
        "    Title: {row['title']}\n",
        "    Genres: {row['genres_clean']}\n",
        "    Overview: {row['overview']}\n",
        "    Cast: {row['cast_clean']}\n",
        "    Crew: {row['crew_clean']}\n",
        "    \"\"\"\n",
        "\n",
        "df['document'] = df.apply(build_movie_document, axis=1)\n",
        "\n",
        "print(\"Movie documents prepared.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batches: 100%|██████████| 151/151 [00:14<00:00, 10.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embeddings generated and stored in ChromaDB.\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: Generate sentence embeddings and store them in ChromaDB\n",
        "\n",
        "# Load embedding model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Create list of documents\n",
        "documents = df['document'].tolist()\n",
        "\n",
        "# Generate embeddings for all documents (can take a moment)\n",
        "embeddings = model.encode(documents, show_progress_bar=True)\n",
        "\n",
        "# Initialize Chroma client and create collection\n",
        "client = chromadb.Client(Settings())\n",
        "collection = client.create_collection(name=\"movies\")\n",
        "\n",
        "# Add documents and embeddings to ChromaDB collection\n",
        "collection.add(\n",
        "    documents=documents,\n",
        "    embeddings=embeddings,\n",
        "    ids=[str(i) for i in range(len(documents))]\n",
        ")\n",
        "\n",
        "print(\"Embeddings generated and stored in ChromaDB.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 5: Define the ARES fallback function to get internet content when needed\n",
        "\n",
        "def get_internet_content(user_query: str):\n",
        "    print(\"Fetching response from ARES live search...\")\n",
        "\n",
        "    url = \"https://api-ares.traversaal.ai/live/predict\"\n",
        "    payload = {\"query\": [user_query]}\n",
        "    headers = {\n",
        "        \"x-api-key\": 'ares',\n",
        "        \"content-type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(url, json=payload, headers=headers)\n",
        "        response.raise_for_status()\n",
        "        return response.json().get('data', {}).get('response_text', \"No response received.\")\n",
        "\n",
        "    except requests.exceptions.HTTPError as http_err:\n",
        "        return f\"HTTP error occurred: {http_err}\"\n",
        "\n",
        "    except requests.exceptions.RequestException as req_err:\n",
        "        return f\"Request error occurred: {req_err}\"\n",
        "\n",
        "    except Exception as err:\n",
        "        return f\"An unexpected error occurred: {err}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 6: Define the query classifier using GPT-4o\n",
        "def classify_query(user_query: str):\n",
        "    router_system_prompt = f\"\"\"\n",
        "    You are a professional query router. Categorize the user's input:\n",
        "    1. \"MOVIE_QUERY\": Any query about a movie/series – including factual questions, reviews, plots, actors, directors, etc.\n",
        "    2. \"INTERNET_QUERY\": For very fresh or real-time data (e.g., new trailers, box office updates, trending news).\n",
        "    3. \"GENERIC_CHAT\": Casual or unrelated conversation.\n",
        "\n",
        "    Examples of MOVIE_QUERY:\n",
        "    - \"Who directed Interstellar?\"\n",
        "    - \"What is Stranger Things about?\"\n",
        "    - \"When is the next season of Breaking Bad?\"\n",
        "\n",
        "    Examples of GENERIC_CHAT:\n",
        "    - \"How are you?\"\n",
        "    - \"Tell me a joke.\"\n",
        "\n",
        "    Respond ONLY with valid JSON:\n",
        "    {{\n",
        "        \"action\": \"MOVIE_QUERY\" or \"INTERNET_QUERY\" or \"GENERIC_CHAT\",\n",
        "        \"reason\": \"brief reason\"\n",
        "    }}\n",
        "\n",
        "    Query: \"{user_query}\"\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = open_router_client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[{\"role\": \"system\", \"content\": router_system_prompt}],\n",
        "            max_tokens=50,  # limit tokens to reduce cost\n",
        "            temperature=0\n",
        "        )\n",
        "        json_text = re.search(r\"\\{.*\\}\", response.choices[0].message.content, re.DOTALL).group()\n",
        "        classification = json.loads(json_text)\n",
        "        return classification\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during classification: {e}\")\n",
        "        return {\"action\": \"GENERIC_CHAT\", \"reason\": \"Fallback due to error.\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 7: Search ChromaDB with embedding similarity\n",
        "\n",
        "def search_chromadb(user_query: str, collection, top_k=5):\n",
        "    query_embedding = model.encode([user_query])[0]\n",
        "    results = collection.query(\n",
        "        query_embeddings=[query_embedding],\n",
        "        n_results=top_k\n",
        "    )\n",
        "    # results['documents'][0] contains the matched documents\n",
        "    return results['documents'][0] if results['documents'] else []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 8: The main agent function combining classification, search, and fallback\n",
        "\n",
        "def movie_agent(user_query: str):\n",
        "    print(f\"Received user query: {user_query}\")\n",
        "\n",
        "    # Step 1: Classify query\n",
        "    classification = classify_query(user_query)\n",
        "    action = classification.get('action')\n",
        "    reason = classification.get('reason')\n",
        "    print(f\"Classification result: {action} (Reason: {reason})\")\n",
        "\n",
        "    if action == \"MOVIE_QUERY\":\n",
        "        results = search_chromadb(user_query, collection)\n",
        "        if results:\n",
        "            print(\"Found recommendations in ChromaDB.\")\n",
        "            # Combine top relevant documents into a context string\n",
        "            context_text = \"\\n\\n\".join(results)\n",
        "\n",
        "            # Prepare system and user prompt for final LLM synthesis\n",
        "            system_prompt = \"You are a helpful movie expert who provides concise summaries based on given context.\"\n",
        "            user_prompt = f\"\"\"Answer the following question using the context below.\n",
        "\n",
        "Question: {user_query}\n",
        "\n",
        "Context:\n",
        "{context_text}\n",
        "\"\"\"\n",
        "\n",
        "            # Call OpenRouter LLM to generate final answer\n",
        "            try:\n",
        "                response = open_router_client.chat.completions.create(\n",
        "                    model=\"gpt-4o\",\n",
        "                    messages=[\n",
        "                        {\"role\": \"system\", \"content\": system_prompt},\n",
        "                        {\"role\": \"user\", \"content\": user_prompt}\n",
        "                    ],\n",
        "                    max_tokens=300,\n",
        "                    temperature=0\n",
        "                )\n",
        "                answer = response.choices[0].message.content.strip()\n",
        "\n",
        "                # Check if answer indicates insufficient info -> fallback to internet\n",
        "                fallback_phrases = [\n",
        "                    \"does not include information\",\n",
        "                    \"no relevant info\",\n",
        "                    \"not found\",\n",
        "                    \"no data\",\n",
        "                    \"no information\",\n",
        "                    \"no relevant documents\",\n",
        "                    \"sorry, i can't help\",\n",
        "                ]\n",
        "                if any(phrase in answer.lower() for phrase in fallback_phrases):\n",
        "                    print(\"LLM answer indicates no relevant info, falling back to internet search.\")\n",
        "                    fallback = get_internet_content(user_query)\n",
        "                    return {\n",
        "                        \"source\": \"ARES\",\n",
        "                        \"answer\": fallback\n",
        "                    }\n",
        "\n",
        "                return {\n",
        "                    \"source\": \"ChromaDB + LLM\",\n",
        "                    \"answer\": answer\n",
        "                }\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error in LLM synthesis: {e}\")\n",
        "                # Fallback to returning raw docs if LLM fails\n",
        "                return {\n",
        "                    \"source\": \"ChromaDB\",\n",
        "                    \"recommendations\": results,\n",
        "                    \"warning\": \"Failed to generate final summary; returning raw results.\"\n",
        "                }\n",
        "\n",
        "        else:\n",
        "            print(\"No good matches found locally. Falling back to ARES.\")\n",
        "            fallback = get_internet_content(user_query)\n",
        "            return {\n",
        "                \"source\": \"ARES\",\n",
        "                \"answer\": fallback\n",
        "            }\n",
        "\n",
        "    elif action == \"INTERNET_QUERY\":\n",
        "        print(\"Routing query to ARES live internet search.\")\n",
        "        fallback = get_internet_content(user_query)\n",
        "        return {\n",
        "            \"source\": \"ARES\",\n",
        "            \"answer\": fallback\n",
        "        }\n",
        "\n",
        "    else:\n",
        "        print(\"Generic chat detected, no movie recommendations.\")\n",
        "        return {\n",
        "            \"source\": \"Agent\",\n",
        "            \"answer\": \"Sorry, I can only help with movie/series queries!\"\n",
        "        }\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def format_response(response, classification_action):\n",
        "    if classification_action == \"MOVIE_QUERY\":\n",
        "        # response['recommendations'] is a list of structured movie docs\n",
        "        return clean_recommendations(response['recommendations'])\n",
        "    elif classification_action == \"INTERNET_QUERY\":\n",
        "        # response['recommendations'] is a plain text string from ARES\n",
        "        return clean_ares_response(response['recommendations'])\n",
        "    else:\n",
        "        return \"No relevant data found.\"\n",
        "\n",
        "def clean_recommendations(raw_recs):\n",
        "    cleaned_recs = []\n",
        "    for rec in raw_recs:\n",
        "        lines = rec.strip().split('\\n')\n",
        "        title = genres = overview = ''\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if line.startswith('Title:'):\n",
        "                title = line[len('Title:'):].strip()\n",
        "            elif line.startswith('Genres:'):\n",
        "                genres = line[len('Genres:'):].strip()\n",
        "            elif line.startswith('Overview:'):\n",
        "                overview = line[len('Overview:'):].strip()\n",
        "        if len(overview) > 200:\n",
        "            overview = overview[:197] + '...'\n",
        "        cleaned = f\"Title: {title}\\nGenres: {genres}\\nOverview: {overview}\\n\"\n",
        "        cleaned_recs.append(cleaned)\n",
        "    return \"\\n---\\n\".join(cleaned_recs)\n",
        "\n",
        "def clean_ares_response(text):\n",
        "    # Remove multiple newlines and trim\n",
        "    import re\n",
        "    text = re.sub(r'\\n\\s*\\n', '\\n\\n', text.strip())\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Received user query: What is The Crown season about?\n",
            "Classification result: MOVIE_QUERY (Reason: The query is asking about the plot of a specific series season.)\n",
            "Found recommendations in ChromaDB.\n",
            "LLM answer indicates no relevant info, falling back to internet search.\n",
            "Fetching response from ARES live search...\n",
            "{'source': 'ARES', 'answer': '1. **What is The Crown season about?**\\n   - \"The Crown\" is a historical drama series that chronicles the life and reign of Queen Elizabeth II. It explores the political rivalries, romances, and significant events that shaped Britain during the second half of the 20th century. The series provides an inside look at the early reign of the queen, who ascended to the throne at the age of 25 after the death of her father, King George VI.\\n\\n2. **The Crown season overview 2025:**\\n   - The sixth and final season of \"The Crown\" was released in two parts. The first part, consisting of four episodes, premiered on November 16, 2023, while the second part, featuring six episodes, was released on December 14, 2023. This season marks the transition into a new millennium and concludes the series, focusing on significant events, including the final weeks of Princess Diana. The creator, Peter Morgan, has confirmed that there will not be a seventh season, marking the end of this long-running series.'}\n",
            "1. **What is The Crown season about?**\n",
            "   - \"The Crown\" is a historical drama series that chronicles the life and reign of Queen Elizabeth II. It explores the political rivalries, romances, and significant events that shaped Britain during the second half of the 20th century. The series provides an inside look at the early reign of the queen, who ascended to the throne at the age of 25 after the death of her father, King George VI.\n",
            "\n",
            "2. **The Crown season overview 2025:**\n",
            "   - The sixth and final season of \"The Crown\" was released in two parts. The first part, consisting of four episodes, premiered on November 16, 2023, while the second part, featuring six episodes, was released on December 14, 2023. This season marks the transition into a new millennium and concludes the series, focusing on significant events, including the final weeks of Princess Diana. The creator, Peter Morgan, has confirmed that there will not be a seventh season, marking the end of this long-running series.\n"
          ]
        }
      ],
      "source": [
        "response = movie_agent(\"What is The Crown season about?\")\n",
        "print(response)\n",
        "\n",
        "# Check source of response to decide how to format\n",
        "if 'ChromaDB' in response.get('source', ''):\n",
        "    # The response from ChromaDB + LLM is a final answer string, not a list of raw recs\n",
        "    answer_text = response['answer']\n",
        "    print(answer_text)  # Just print the final LLM-generated summary\n",
        "elif response.get('source') == 'ARES':\n",
        "    internet_text = response['answer']\n",
        "    print(clean_ares_response(internet_text))\n",
        "else:\n",
        "    print(\"No recommendations found or unknown source.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Received user query: When is the next season of stranger things coming?\n",
            "Classification result: MOVIE_QUERY (Reason: The query is about the release of the next season of a series.)\n",
            "Found recommendations in ChromaDB.\n",
            "No recommendations found or unknown source.\n"
          ]
        }
      ],
      "source": [
        "response = movie_agent(\"When is the next season of stranger things coming?\")\n",
        "\n",
        "# Check source of response to decide how to format\n",
        "if response.get('source') == 'ChromaDB':\n",
        "    raw_recs = response['answer']\n",
        "    print(clean_recommendations(raw_recs))\n",
        "elif response.get('source') == 'ARES':\n",
        "    # Plain text from internet query — just print it nicely\n",
        "    internet_text = response['answer']\n",
        "    print(clean_ares_response(internet_text))\n",
        "else:\n",
        "    print(\"No recommendations found or unknown source.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "3.10.13",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
