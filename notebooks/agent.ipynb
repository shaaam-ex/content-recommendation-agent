{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/exton/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported and globals ready.\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Import necessary libraries and initialize global variables\n",
        "\n",
        "import pandas as pd\n",
        "import ast\n",
        "import re\n",
        "import json\n",
        "import requests\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import chromadb\n",
        "from chromadb.config import Settings\n",
        "\n",
        "# For calling the LLM router (OpenRouter client or OpenAI client)\n",
        "from openai import OpenAIError\n",
        "\n",
        "# Assuming open_router_client and ares_api_key are configured elsewhere in your environment\n",
        "\n",
        "print(\"Libraries imported and globals ready.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Time to give this output to an LLM\n",
        "import openai\n",
        "\n",
        "open_router_client = openai.OpenAI(\n",
        "    api_key=\"api-key\",\n",
        "    base_url=\"https://openrouter.ai/api/v1\" \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data loaded and cleaned.\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Load datasets, merge and clean relevant fields\n",
        "\n",
        "movies_df = pd.read_csv('../data/tmdb_5000_movies.csv')\n",
        "credits_df = pd.read_csv('../data/tmdb_5000_credits.csv')\n",
        "\n",
        "# Merge on movie title\n",
        "df = movies_df.merge(credits_df, on='title')\n",
        "\n",
        "# Helper function to parse JSON-like strings and extract 'name' fields\n",
        "def extract_names(json_str, top_n=None):\n",
        "    try:\n",
        "        items = ast.literal_eval(json_str)\n",
        "        names = [item['name'] for item in items]\n",
        "        if top_n:\n",
        "            names = names[:top_n]\n",
        "        return ', '.join(names)\n",
        "    except (ValueError, SyntaxError):\n",
        "        return ''\n",
        "\n",
        "# Apply the helper to genres, cast, and crew columns\n",
        "df['genres_clean'] = df['genres'].apply(lambda x: extract_names(x))\n",
        "df['cast_clean'] = df['cast'].apply(lambda x: extract_names(x, top_n=5))\n",
        "df['crew_clean'] = df['crew'].apply(lambda x: extract_names(x, top_n=5))\n",
        "\n",
        "print(\"Data loaded and cleaned.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Movie documents prepared.\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Build a single descriptive text block per movie for embedding\n",
        "\n",
        "def build_movie_document(row):\n",
        "    return f\"\"\"\n",
        "    Title: {row['title']}\n",
        "    Genres: {row['genres_clean']}\n",
        "    Overview: {row['overview']}\n",
        "    Cast: {row['cast_clean']}\n",
        "    Crew: {row['crew_clean']}\n",
        "    \"\"\"\n",
        "\n",
        "df['document'] = df.apply(build_movie_document, axis=1)\n",
        "\n",
        "print(\"Movie documents prepared.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batches: 100%|██████████| 151/151 [00:14<00:00, 10.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embeddings generated and stored in ChromaDB.\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: Generate sentence embeddings and store them in ChromaDB\n",
        "\n",
        "# Load embedding model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Create list of documents\n",
        "documents = df['document'].tolist()\n",
        "\n",
        "# Generate embeddings for all documents (can take a moment)\n",
        "embeddings = model.encode(documents, show_progress_bar=True)\n",
        "\n",
        "# Initialize Chroma client and create collection\n",
        "client = chromadb.Client(Settings())\n",
        "collection = client.create_collection(name=\"movies\")\n",
        "\n",
        "# Add documents and embeddings to ChromaDB collection\n",
        "collection.add(\n",
        "    documents=documents,\n",
        "    embeddings=embeddings,\n",
        "    ids=[str(i) for i in range(len(documents))]\n",
        ")\n",
        "\n",
        "print(\"Embeddings generated and stored in ChromaDB.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 5: Define the ARES fallback function to get internet content when needed\n",
        "\n",
        "def get_internet_content(user_query: str):\n",
        "    print(\"Fetching response from ARES live search...\")\n",
        "\n",
        "    url = \"https://api-ares.traversaal.ai/live/predict\"\n",
        "    payload = {\"query\": [user_query]}\n",
        "    headers = {\n",
        "        \"x-api-key\": 'ares',\n",
        "        \"content-type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(url, json=payload, headers=headers)\n",
        "        response.raise_for_status()\n",
        "        return response.json().get('data', {}).get('response_text', \"No response received.\")\n",
        "\n",
        "    except requests.exceptions.HTTPError as http_err:\n",
        "        return f\"HTTP error occurred: {http_err}\"\n",
        "\n",
        "    except requests.exceptions.RequestException as req_err:\n",
        "        return f\"Request error occurred: {req_err}\"\n",
        "\n",
        "    except Exception as err:\n",
        "        return f\"An unexpected error occurred: {err}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 6: Define the query classifier using GPT-4o\n",
        "def classify_query(user_query: str):\n",
        "    router_system_prompt = f\"\"\"\n",
        "    You are a professional query router. Categorize the user's input:\n",
        "    1. \"MOVIE_QUERY\": For movie/series recommendations.\n",
        "    2. \"INTERNET_QUERY\": For fresh internet data (reviews, trailers).\n",
        "    3. \"GENERIC_CHAT\": For casual or unrelated chat.\n",
        "\n",
        "    Examples of GENERIC_CHAT:\n",
        "    - \"How are you?\"\n",
        "    - \"What's up?\"\n",
        "    - \"Tell me a joke.\"\n",
        "\n",
        "    Examples of NON-GENERIC queries (should return \"No\"):\n",
        "    - \"Who directed Interstellar?\"\n",
        "    - \"What is Stranger Things about?\"\n",
        "    - \"When is the next season of Breaking Bad?\"\n",
        "\n",
        "    Respond ONLY with a valid JSON in this format:\n",
        "    {{\n",
        "        \"action\": \"MOVIE_QUERY\" or \"INTERNET_QUERY\" or \"GENERIC_CHAT\",\n",
        "        \"reason\": \"brief reason\"\n",
        "    }}\n",
        "\n",
        "    Query: \"{user_query}\"\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = open_router_client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[{\"role\": \"system\", \"content\": router_system_prompt}],\n",
        "            max_tokens=50,  # limit tokens to reduce cost\n",
        "            temperature=0\n",
        "        )\n",
        "        json_text = re.search(r\"\\{.*\\}\", response.choices[0].message.content, re.DOTALL).group()\n",
        "        classification = json.loads(json_text)\n",
        "        return classification\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during classification: {e}\")\n",
        "        return {\"action\": \"GENERIC_CHAT\", \"reason\": \"Fallback due to error.\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 7: Search ChromaDB with embedding similarity\n",
        "\n",
        "def search_chromadb(user_query: str, collection, top_k=5):\n",
        "    query_embedding = model.encode([user_query])[0]\n",
        "    results = collection.query(\n",
        "        query_embeddings=[query_embedding],\n",
        "        n_results=top_k\n",
        "    )\n",
        "    # results['documents'][0] contains the matched documents\n",
        "    return results['documents'][0] if results['documents'] else []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 8: The main agent function combining classification, search, and fallback\n",
        "\n",
        "def movie_agent(user_query: str):\n",
        "    print(f\"Received user query: {user_query}\")\n",
        "\n",
        "    # Step 1: Classify query\n",
        "    classification = classify_query(user_query)\n",
        "    action = classification.get('action')\n",
        "    reason = classification.get('reason')\n",
        "    print(f\"Classification result: {action} (Reason: {reason})\")\n",
        "\n",
        "    if action == \"MOVIE_QUERY\":\n",
        "        results = search_chromadb(user_query, collection)\n",
        "        if results:\n",
        "            print(\"Found recommendations in ChromaDB.\")\n",
        "            return {\n",
        "                \"source\": \"ChromaDB\",\n",
        "                \"recommendations\": results\n",
        "            }\n",
        "        else:\n",
        "            print(\"No good matches found locally. Falling back to ARES.\")\n",
        "            fallback = get_internet_content(user_query)\n",
        "            return {\n",
        "                \"source\": \"ARES\",\n",
        "                \"recommendations\": fallback\n",
        "            }\n",
        "\n",
        "    elif action == \"INTERNET_QUERY\":\n",
        "        print(\"Routing query to ARES live internet search.\")\n",
        "        fallback = get_internet_content(user_query)\n",
        "        return {\n",
        "            \"source\": \"ARES\",\n",
        "            \"recommendations\": fallback\n",
        "        }\n",
        "\n",
        "    else:\n",
        "        print(\"Generic chat detected, no movie recommendations.\")\n",
        "        return {\n",
        "            \"source\": \"Agent\",\n",
        "            \"recommendations\": \"Sorry, I can only help with movie/series queries!\"\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def format_response(response, classification_action):\n",
        "    if classification_action == \"MOVIE_QUERY\":\n",
        "        # response['recommendations'] is a list of structured movie docs\n",
        "        return clean_recommendations(response['recommendations'])\n",
        "    elif classification_action == \"INTERNET_QUERY\":\n",
        "        # response['recommendations'] is a plain text string from ARES\n",
        "        return clean_ares_response(response['recommendations'])\n",
        "    else:\n",
        "        return \"No relevant data found.\"\n",
        "\n",
        "def clean_recommendations(raw_recs):\n",
        "    cleaned_recs = []\n",
        "    for rec in raw_recs:\n",
        "        lines = rec.strip().split('\\n')\n",
        "        title = genres = overview = ''\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if line.startswith('Title:'):\n",
        "                title = line[len('Title:'):].strip()\n",
        "            elif line.startswith('Genres:'):\n",
        "                genres = line[len('Genres:'):].strip()\n",
        "            elif line.startswith('Overview:'):\n",
        "                overview = line[len('Overview:'):].strip()\n",
        "        if len(overview) > 200:\n",
        "            overview = overview[:197] + '...'\n",
        "        cleaned = f\"Title: {title}\\nGenres: {genres}\\nOverview: {overview}\\n\"\n",
        "        cleaned_recs.append(cleaned)\n",
        "    return \"\\n---\\n\".join(cleaned_recs)\n",
        "\n",
        "def clean_ares_response(text):\n",
        "    # Remove multiple newlines and trim\n",
        "    import re\n",
        "    text = re.sub(r'\\n\\s*\\n', '\\n\\n', text.strip())\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Received user query: Who directed The Chronicles of Narnia?\n",
            "Classification result: MOVIE_QUERY (Reason: The query is asking for information about a movie's director.)\n",
            "Found recommendations in ChromaDB.\n",
            "{'source': 'ChromaDB', 'recommendations': ['\\n    Title: The Chronicles of Narnia: Prince Caspian\\n    Genres: Adventure, Family, Fantasy\\n    Overview: One year after their incredible adventures in the Lion, the Witch and the Wardrobe, Peter, Edmund, Lucy and Susan Pevensie return to Narnia to aid a young prince whose life has been threatened by the evil King Miraz. Now, with the help of a colorful cast of new characters, including Trufflehunter the badger and Nikabrik the dwarf, the Pevensie clan embarks on an incredible quest to ensure that Narnia is returned to its rightful heir.\\n    Cast: Ben Barnes, William Moseley, Anna Popplewell, Skandar Keynes, Georgie Henley\\n    Crew: Liz Mullane, Gail Stevens, David Minkowski, Matthew Stillman, Mark Johnson\\n    ', \"\\n    Title: The Chronicles of Narnia: The Lion, the Witch and the Wardrobe\\n    Genres: Adventure, Family, Fantasy\\n    Overview: Siblings Lucy, Edmund, Susan and Peter step through a magical wardrobe and find the land of Narnia. There, the they discover a charming, once peaceful kingdom that has been plunged into eternal winter by the evil White Witch, Jadis. Aided by the wise and magnificent lion, Aslan, the children lead Narnia into a spectacular, climactic battle to be free of the Witch's glacial powers forever.\\n    Cast: William Moseley, Anna Popplewell, Skandar Keynes, Georgie Henley, Liam Neeson\\n    Crew: Donald McAlpine, David Minkowski, Matthew Stillman, Mark Johnson, Andrew Adamson\\n    \", '\\n    Title: The Chronicles of Narnia: The Voyage of the Dawn Treader\\n    Genres: Adventure, Family, Fantasy\\n    Overview: This time around Edmund and Lucy Pevensie, along with their pesky cousin Eustace Scrubb find themselves swallowed into a painting and on to a fantastic Narnian ship headed for the very edges of the world.\\n    Cast: Skandar Keynes, Georgie Henley, Simon Pegg, Gary Sweet, Arthur Angel\\n    Crew: Mark Robins, Rick Shaine, Mark Johnson, Andrew Adamson, C. S. Lewis\\n    ', '\\n    Title: Dragonslayer\\n    Genres: Fantasy\\n    Overview: The sorcerer and his apprentice Galen are on a mission to kill an evil dragon in order to save the King’s daughter from being sacrificed in accordance to a pact that the King himself made with the dragon to protect his kingdom. A fantasy film from Disney Studios that exhausted all possible visual effects of the time.\\n    Cast: Peter MacNicol, Caitlin Clarke, Ralph Richardson, John Hallam, Peter Eyre\\n    Crew: Elliot Scott, Howard W. Koch, Derek Vanlint, Ian Whittaker, Alex North\\n    ', '\\n    Title: Anaconda\\n    Genres: Adventure, Horror, Thriller\\n    Overview: A \"National Geographic\" film crew is taken hostage by an insane hunter, who takes them along on his quest to capture the world\\'s largest - and deadliest - snake.\\n    Cast: Jennifer Lopez, Ice Cube, Jon Voight, Eric Stoltz, Owen Wilson\\n    Crew: John Papsidera, Bill Butler, Webster Whinery, Michael R. Miller, Mindy Marin\\n    ']}\n"
          ]
        }
      ],
      "source": [
        "response = movie_agent(\"Who directed The Chronicles of Narnia?\")\n",
        "print(response)\n",
        "\n",
        "# Check source of response to decide how to format\n",
        "# if response.get('source') == 'ChromaDB':\n",
        "#     raw_recs = response['recommendations']\n",
        "#     print(clean_recommendations(raw_recs))\n",
        "# elif response.get('source') == 'ARES':\n",
        "#     # Plain text from internet query — just print it nicely\n",
        "#     internet_text = response['recommendations']\n",
        "#     print(clean_ares_response(internet_text))\n",
        "# else:\n",
        "#     print(\"No recommendations found or unknown source.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Received user query: When is the next season of stranger things coming?\n",
            "Classification result: INTERNET_QUERY (Reason: The user is asking for the release date of a new season, which requires current internet data.)\n",
            "Routing query to ARES live internet search.\n",
            "Fetching response from ARES live search...\n",
            "The next season of \"Stranger Things,\" which is Season 5, is set to premiere in 2025. \n",
            "\n",
            "1. **Release Date**: The fifth and final season of \"Stranger Things\" will be released in 2025. Specific details about the exact date have not been confirmed yet, but it has been officially announced by Netflix.\n",
            "\n",
            "2. **Production Status**: Production on Season 5 has officially wrapped, indicating that the show is in the post-production phase.\n",
            "\n",
            "For more information, you can check the following sources:\n",
            "- [Netflix - Everything We Know So Far](https://www.netflix.com/tudum/articles/the-title-of-stranger-things-season-5-episode-1-revealed)\n",
            "- [Wikipedia - Stranger Things Season 5](https://en.wikipedia.org/wiki/Stranger_Things_season_5)\n"
          ]
        }
      ],
      "source": [
        "response = movie_agent(\"When is the next season of stranger things coming?\")\n",
        "\n",
        "# Check source of response to decide how to format\n",
        "if response.get('source') == 'ChromaDB':\n",
        "    raw_recs = response['recommendations']\n",
        "    print(clean_recommendations(raw_recs))\n",
        "elif response.get('source') == 'ARES':\n",
        "    # Plain text from internet query — just print it nicely\n",
        "    internet_text = response['recommendations']\n",
        "    print(clean_ares_response(internet_text))\n",
        "else:\n",
        "    print(\"No recommendations found or unknown source.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "3.10.13",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
